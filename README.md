# ğŸ« ClasificaciÃ³n de NeumonÃ­a con VisiÃ³n por Computador

**Trabajo 3 - VisiÃ³n por Computador**  
**Universidad Nacional de Colombia - Facultad de Minas**

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa y compara sistemas de clasificaciÃ³n de imÃ¡genes mÃ©dicas (radiografÃ­as de tÃ³rax) para detectar neumonÃ­a utilizando dos enfoques:

1. **Descriptores ClÃ¡sicos** (*handcrafted features*) + Clasificadores tradicionales (SVM, Random Forest, k-NN, Logistic Regression)
2. **Deep Learning** con Redes Neuronales Convolucionales (CNNs) - *Parte 4 (opcional)*

## ğŸ¯ Objetivos

- Explorar y preprocesar un dataset mÃ©dico de radiografÃ­as
- Implementar descriptores de forma y textura desde conceptos de visiÃ³n por computador
- Entrenar y evaluar clasificadores tradicionales
- Comparar rendimiento entre diferentes enfoques
- Documentar el proceso completo en un pipeline reproducible

## ğŸ“Š Dataset

**Chest X-Ray Pneumonia Detection**  
[Kaggle Dataset](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)

- **Train**: ~5,216 imÃ¡genes (1,341 NORMAL | 3,875 PNEUMONIA)
- **Test**: ~624 imÃ¡genes
- **Validation**: ~16 imÃ¡genes
- **Formato**: JPEG, dimensiones variables
- **Desbalance**: 3:1 (Pneumonia:Normal)

## ğŸ—ï¸ Estructura del Proyecto

```
clasificacion-neumonia-vision/
â”œâ”€â”€ README.md                                    # Este archivo
â”œâ”€â”€ requirements.txt                             # Dependencias del proyecto
â”œâ”€â”€ Trabajo03.md                                 # Enunciado del trabajo
â”œâ”€â”€ data/                                        # Datasets (descargados automÃ¡ticamente)
â”‚   â””â”€â”€ datasets/
â”‚       â””â”€â”€ paultimothymooney/
â”‚           â””â”€â”€ chest-xray-pneumonia/
â”‚               â””â”€â”€ versions/2/chest_xray/
â”‚                   â”œâ”€â”€ train/
â”‚                   â”œâ”€â”€ test/
â”‚                   â””â”€â”€ val/
â”œâ”€â”€ notebooks/                                   # Notebooks de Jupyter
â”‚   â”œâ”€â”€ 01_exploracion_y_preprocesamiento.ipynb  # AnÃ¡lisis EDA + CLAHE
â”‚   â”œâ”€â”€ 02_extraccion_de_descriptores.ipynb      # HOG, LBP, GLCM, Gabor, etc.
â”‚   â”œâ”€â”€ 03_clasificacion_con_descriptores_clasicos.ipynb  # SVM, RF, k-NN, LR, CNN.
â””â”€â”€ results/                                     # Resultados generados
    â”œâ”€â”€ features_classical.npz                   # CaracterÃ­sticas extraÃ­das
    â””â”€â”€ figures/                                 # Visualizaciones
```

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- **Python 3.10+** (recomendado: 3.11 o 3.12)
- **Anaconda/Miniconda** (opcional pero recomendado)
- **Cuenta de Kaggle** (para descarga automÃ¡tica del dataset)

### ConfiguraciÃ³n en macOS y Linux

```bash
# 1. Clonar el repositorio
git clone https://github.com/tu-usuario/clasificacion-neumonia-vision.git
cd clasificacion-neumonia-vision

# 2. Crear entorno virtual
python3 -m venv .venv

# 3. Activar entorno
source .venv/bin/activate

# 4. Instalar dependencias
pip install --upgrade pip
pip install -r requirements.txt

# 5. Configurar Jupyter (si no estÃ¡ instalado globalmente)
python -m ipykernel install --user --name=.venv --display-name "Python (Pneumonia)"

# 6. Lanzar Jupyter
jupyter notebook
```

### ConfiguraciÃ³n en Windows

```cmd
# 1. Clonar el repositorio
git clone https://github.com/tu-usuario/clasificacion-neumonia-vision.git
cd clasificacion-neumonia-vision

# 2. Crear entorno virtual
python -m venv .venv

# 3. Activar entorno
.venv\Scripts\activate

# 4. Instalar dependencias
pip install --upgrade pip
pip install -r requirements.txt

# 5. Configurar Jupyter
python -m ipykernel install --user --name=.venv --display-name "Python (Pneumonia)"

# 6. Lanzar Jupyter
jupyter notebook
```

### ConfiguraciÃ³n de Kaggle API (Descarga AutomÃ¡tica)

El dataset se descarga automÃ¡ticamente al ejecutar los notebooks. Para que funcione:

1. **Crear cuenta en Kaggle**: [kaggle.com](https://www.kaggle.com)
2. **Generar API Token**:
   - Ir a: Account â†’ API â†’ Create New API Token
   - Se descarga `kaggle.json`
3. **Configurar credenciales**:
   ```bash
   # macOS/Linux
   mkdir -p ~/.kaggle
   cp kaggle.json ~/.kaggle/
   chmod 600 ~/.kaggle/kaggle.json
   
   # Windows
   mkdir %USERPROFILE%\.kaggle
   copy kaggle.json %USERPROFILE%\.kaggle\
   ```

## ğŸš€ Uso del Proyecto

### Generar Figuras para el Blog Post

Para generar todas las visualizaciones necesarias para el blog post de GitHub Pages:

```bash
# Ejecutar manualmente desde Jupyter
jupyter notebook
# Luego ejecutar todos los notebooks en orden
```

**Figuras generadas**:
- `01_muestras_radiografias.png` â€” Ejemplos de imÃ¡genes NORMAL y PNEUMONIA
- `02_distribucion_clases.png` â€” DistribuciÃ³n del dataset
- `03_comparacion_clahe.png` â€” ComparaciÃ³n entre CLAHE y ecualizaciÃ³n estÃ¡ndar
- `04_hog_visualization.png` â€” VisualizaciÃ³n del descriptor HOG
- `05_lbp_visualization.png` â€” VisualizaciÃ³n del descriptor LBP
- `06_gabor_filters.png` â€” Banco de filtros de Gabor
- `07_feature_distributions.png` â€” Distribuciones de caracterÃ­sticas discriminativas
- `08_top_discriminative_features.png` â€” Top 20 caracterÃ­sticas (Cohenâ€™s d)
- `09_pca_2d_visualization.png` â€” ProyecciÃ³n PCA en 2D
- `10_pca_variance_explained.png` â€” Varianza explicada por cada componente principal
- `11_cv_comparison.png` â€” ComparaciÃ³n de desempeÃ±o en validaciÃ³n cruzada
- `12_metrics_comparison.png` â€” ComparaciÃ³n global de mÃ©tricas de los modelos
- `13_confusion_matrices.png` â€” Matrices de confusiÃ³n de **todos los modelos clÃ¡sicos**
- `14_roc_curves.png` â€” Curvas ROC comparadas
- `15_feature_importance.png` â€” Importancia de caracterÃ­sticas segÃºn Random Forest
- `16_confusion_matrix_cnn.png` â€” Matriz de confusiÃ³n del modelo CNN
- `17_roc_cnn.png` â€” Curva **ROC** del modelo CNN

### Copiar Figuras a GitHub Pages

```bash
# Crear carpeta de assets
mkdir -p docs/assets/images

# Copiar todas las figuras
cp results/figures/*.png docs/assets/images/

# Verificar
ls docs/assets/images/
```

### Orden de EjecuciÃ³n de Notebooks

1. **`01_exploracion_y_preprocesamiento.ipynb`**
   - Descarga automÃ¡tica del dataset
   - AnÃ¡lisis de distribuciÃ³n de clases
   - ImplementaciÃ³n de CLAHE (mejora de contraste)
   - VisualizaciÃ³n de preprocesamiento

2. **`02_extraccion_de_descriptores.ipynb`**
   - **Descriptores de Forma**:
     - HOG (Histogram of Oriented Gradients)
     - Momentos de Hu (7 invariantes)
     - Descriptores de Contorno (Ã¡rea, perÃ­metro, circularidad, excentricidad)
   - **Descriptores de Textura**:
     - LBP (Local Binary Patterns)
     - GLCM (Gray Level Co-occurrence Matrix)
     - Filtros de Gabor
     - EstadÃ­sticas de Primer Orden
   - ConstrucciÃ³n de matriz de caracterÃ­sticas
   - Guardado de features en `results/features_classical.npz`

3. **`03_clasificacion_con_descriptores_clasicos.ipynb`**
   - NormalizaciÃ³n con StandardScaler
   - ReducciÃ³n de dimensionalidad (PCA)
   - Entrenamiento de clasificadores:
     - Logistic Regression
     - SVM (Linear y RBF)
     - Random Forest
     - k-NN
   - ValidaciÃ³n cruzada estratificada (5-Fold)
   - Entrenamiento de CNN
   - EvaluaciÃ³n con mÃ©tricas:
     - Accuracy, Precision, Recall, F1-Score
     - Matrices de ConfusiÃ³n
     - Curvas ROC y AUC
   - AnÃ¡lisis de importancia de caracterÃ­sticas
   - OptimizaciÃ³n de hiperparÃ¡metros (GridSearchCV)

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas Clave

- **Accuracy**: PrecisiÃ³n general del modelo
- **Recall (Sensibilidad)**: **CRÃTICO** - Minimizar falsos negativos (no detectar neumonÃ­a)
- **F1-Score**: Balance entre precisiÃ³n y recall
- **AUC-ROC**: Capacidad discriminativa del modelo

### Baseline de Referencia

Debido al desbalance (74.3% Pneumonia), un clasificador que siempre prediga "Pneumonia" obtendrÃ­a:
- **Accuracy Base**: 74.3%
- **Recall Base**: 100% (pero con muchos falsos positivos)

**Meta**: Superar significativamente este baseline con modelos entrenados.

## ğŸ§ª TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­as |
|-----------|-------------|
| **Lenguaje** | Python 3.10+ |
| **Procesamiento de ImÃ¡genes** | OpenCV, scikit-image |
| **Machine Learning** | scikit-learn, scipy, tensorflow |
| **VisualizaciÃ³n** | matplotlib, seaborn |
| **Notebooks** | Jupyter, IPython |
| **GestiÃ³n de Datos** | NumPy, pandas |
| **Descarga de Datasets** | kagglehub |

## ğŸ“š Conceptos Implementados

### Preprocesamiento
- âœ… NormalizaciÃ³n de tamaÃ±o (224x224)
- âœ… CLAHE (Contrast Limited Adaptive Histogram Equalization)
- âœ… BinarizaciÃ³n con Otsu

### Descriptores de Forma
- âœ… **HOG**: Detecta bordes y estructuras (costillas, clavÃ­culas)
- âœ… **Momentos de Hu**: Invariantes a traslaciÃ³n, escala y rotaciÃ³n
- âœ… **Contornos**: CaracterizaciÃ³n geomÃ©trica de regiones pulmonares

### Descriptores de Textura
- âœ… **LBP**: Patrones locales de textura
- âœ… **GLCM**: Relaciones espaciales entre pÃ­xeles
- âœ… **Gabor**: Filtros direccionales multi-frecuencia
- âœ… **EstadÃ­sticas**: Media, varianza, skewness, kurtosis, entropÃ­a

### Clasificadores
- âœ… SVM (kernels linear y RBF)
- âœ… Random Forest (con anÃ¡lisis de importancia)
- âœ… k-NN (vecinos cercanos)
- âœ… Logistic Regression
- âœ… Convolutional Neural Networks

### EvaluaciÃ³n
- âœ… ValidaciÃ³n cruzada estratificada
- âœ… MÃ©tricas robustas al desbalance
- âœ… Matrices de confusiÃ³n
- âœ… Curvas ROC
- âœ… OptimizaciÃ³n de hiperparÃ¡metros

## ğŸ”§ SoluciÃ³n de Problemas

### Error: `ValueError` en histogramas (NumPy 2.2.6)

**Problema**: Incompatibilidad entre NumPy 2.2.6 y matplotlib.

**SoluciÃ³n aplicada**: Uso de `np.bincount()` en lugar de `np.histogram()`.

### Dataset no se descarga

**Causas**:
1. No hay credenciales de Kaggle configuradas
2. Red bloqueando Kaggle API

**SoluciÃ³n**:
```bash
# Verificar configuraciÃ³n
cat ~/.kaggle/kaggle.json

# Descargar manualmente desde: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
# Descomprimir en: data/datasets/paultimothymooney/chest-xray-pneumonia/
```

### Kernel de Jupyter no aparece

```bash
python -m ipykernel install --user --name=.venv --display-name "Python (Pneumonia)"
jupyter kernelspec list  # Verificar instalaciÃ³n
```

## ğŸ‘¥ Equipo

**Grupo:** Grillo Digital  
**Integrantes:**
- Juan Pablo Palacio PÃ©rez - [juppalaciope@unal.edu.co](mailto:juppalaciope@unal.edu.co)
- David Giraldo Valencia - [dgiraldova@unal.edu.co](mailto:dgiraldova@unal.edu.co)
- AndrÃ©s Felipe Moreno Calle - [amorenocal@unal.edu.co](mailto:amorenocal@unal.edu.co)
- VÃ­ctor Manuel VelÃ¡squez Cabeza - [vivelasquezc@unal.edu.co](mailto:vivelasquezc@unal.edu.co)

## ğŸ“– Referencias

1. Kermany, D. et al. (2018). *Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning*. Cell.
2. Dalal, N. & Triggs, B. (2005). *Histograms of Oriented Gradients for Human Detection*. CVPR.
3. Ojala, T. et al. (2002). *Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns*. PAMI.
4. Haralick, R.M. et al. (1973). *Textural Features for Image Classification*. IEEE Transactions on Systems, Man, and Cybernetics.
5. [PyImageSearch - Hu Moments](https://pyimagesearch.com/2014/10/27/opencv-shape-descriptor-hu-moments-example/)

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico para la Universidad Nacional de Colombia.

## ğŸ™ Agradecimientos

- Profesor: Juan David Ospina Arango
- Monitor: AndrÃ©s Mauricio Zapata
- Dataset: Paul Mooney (Kaggle)

---

**Ãšltima actualizaciÃ³n**: Diciembre 2025
