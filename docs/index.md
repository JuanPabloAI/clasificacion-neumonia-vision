---
layout: default
title: Clasificaci√≥n de Neumon√≠a en Radiograf√≠as de T√≥rax
description: Comparaci√≥n de Descriptores Cl√°sicos vs Deep Learning
---

# Clasificaci√≥n de Neumon√≠a en Radiograf√≠as de T√≥rax
## Descriptores Handcrafted vs Deep Learning

**Equipo:** Grillo Digital

**Autores:**  
Juan Pablo Palacio P√©rez, David Giraldo Valencia, Andr√©s Felipe Moreno Calle, V√≠ctor Manuel Vel√°squez Cabeza

**Curso:** Visi√≥n por Computador 3009228 - Semestre 2025-02  
**Instituci√≥n:** Universidad Nacional de Colombia - Facultad de Minas  
**Profesor:** Juan David Ospina Arango

---

## üìã Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Marco Te√≥rico](#marco-te√≥rico)
3. [Metodolog√≠a](#metodolog√≠a)
4. [Experimentos y Resultados](#experimentos-y-resultados)
5. [An√°lisis y Discusi√≥n](#an√°lisis-y-discusi√≥n)
6. [Conclusiones](#conclusiones)
7. [Referencias](#referencias)
8. [An√°lisis de Contribuci√≥n Individual](#an√°lisis-de-contribuci√≥n-individual)

---

## 1. Introducci√≥n

### 1.1 Contexto y Motivaci√≥n

La neumon√≠a es una de las principales causas de mortalidad infantil a nivel mundial, responsable de aproximadamente el 15% de todas las muertes en ni√±os menores de 5 a√±os [[1]](#ref1). El diagn√≥stico temprano y preciso mediante radiograf√≠as de t√≥rax es crucial para iniciar el tratamiento adecuado y mejorar los resultados cl√≠nicos.

La interpretaci√≥n de radiograf√≠as de t√≥rax requiere experiencia m√©dica especializada y puede verse afectada por la variabilidad inter-observador. En este contexto, los sistemas de asistencia al diagn√≥stico basados en visi√≥n por computador pueden ser herramientas valiosas para:

- **Reducir tiempos de diagn√≥stico** en entornos cl√≠nicos con alta demanda
- **Proporcionar segundas opiniones** para apoyar decisiones m√©dicas
- **Democratizar el acceso** a diagn√≥sticos de calidad en regiones con recursos limitados
- **Servir como herramientas educativas** para profesionales en formaci√≥n

### 1.2 Objetivos del Proyecto

Este trabajo tiene como objetivo **comparar dos enfoques fundamentales** en visi√≥n por computador para la clasificaci√≥n de im√°genes m√©dicas:

1. **Descriptores Handcrafted (Cl√°sicos)**: Extracci√≥n manual de caracter√≠sticas de forma y textura combinadas con clasificadores tradicionales de Machine Learning
2. **Deep Learning**: Redes neuronales convolucionales que aprenden representaciones autom√°ticamente de los datos

**No buscamos** superar el estado del arte en clasificaci√≥n de neumon√≠a, sino **explorar y validar** conceptos fundamentales de visi√≥n por computador, implementando un pipeline completo de reconocimiento de patrones desde cero.

### 1.3 Dataset

Utilizamos el dataset **Chest X-Ray Pneumonia** disponible en Kaggle [[2]](#ref2), que contiene:

| Conjunto | NORMAL | PNEUMONIA | Total |
|----------|--------|-----------|-------|
| Entrenamiento | 1,341 | 3,875 | 5,216 |
| Prueba | 234 | 390 | 624 |
| Validaci√≥n | 8 | 8 | 16 |

**Caracter√≠sticas del dataset:**
- Radiograf√≠as de t√≥rax en escala de grises
- Tama√±os variables (originalmente entre 400-3000 p√≠xeles)
- **Desbalance de clases**: ~3:1 (Neumon√≠a:Normal)
- Provenientes de ni√±os de 1 a 5 a√±os en Guangzhou, China

---

## 2. Marco Te√≥rico

### 2.1 Descriptores de Forma

#### 2.1.1 Histogram of Oriented Gradients (HOG)

HOG [[3]](#ref3) es un descriptor que captura la distribuci√≥n de gradientes de intensidad en una imagen. Es particularmente √∫til para detectar estructuras como bordes de costillas y clav√≠culas en radiograf√≠as.

**Principio:** Divide la imagen en celdas peque√±as (8√ó8 p√≠xeles), calcula histogramas de orientaciones de gradientes en cada celda, y normaliza por bloques (3√ó3 celdas) para robustez ante cambios de iluminaci√≥n.

**Par√°metros implementados:**
- 9 orientaciones (bins angulares de 0¬∞ a 180¬∞)
- Celdas de 8√ó8 p√≠xeles
- Bloques de 3√ó3 celdas
- Normalizaci√≥n L2-Hys

#### 2.1.2 Momentos de Hu

Los 7 momentos invariantes de Hu [[4]](#ref4) caracterizan la forma global de objetos mediante funciones de los momentos centrales de la imagen. Son **invariantes** a:
- **Traslaci√≥n**: Posici√≥n del objeto en la imagen
- **Escala**: Tama√±o del objeto
- **Rotaci√≥n**: Orientaci√≥n del objeto

Aplicamos transformaci√≥n logar√≠tmica para normalizar la escala de magnitud y clipping para evitar valores extremos.

#### 2.1.3 Descriptores de Contorno

Extraemos caracter√≠sticas geom√©tricas del contorno m√°s grande detectado (regi√≥n pulmonar):

- **√Årea**: Tama√±o de la regi√≥n pulmonar
- **Per√≠metro**: Longitud del contorno
- **Circularidad**: `4œÄ √ó √°rea / per√≠metro¬≤` (1.0 = c√≠rculo perfecto)
- **Excentricidad**: Medida de "alargamiento" mediante ajuste de elipse

### 2.2 Descriptores de Textura

#### 2.2.1 Local Binary Patterns (LBP)

LBP [[5]](#ref5) codifica la textura local comparando cada p√≠xel con sus vecinos en un radio espec√≠fico. Es excelente para detectar patrones repetitivos en tejido pulmonar.

**Configuraci√≥n:**
- 24 puntos vecinos (mayor robustez que el cl√°sico 8-puntos)
- Radio de 3 p√≠xeles
- M√©todo 'uniform' (reduce dimensionalidad a 26 patrones m√°s frecuentes)

#### 2.2.2 Gray Level Co-occurrence Matrix (GLCM)

GLCM [[6]](#ref6) mide relaciones espaciales entre p√≠xeles a diferentes direcciones y distancias. Extraemos 5 propiedades estad√≠sticas:

1. **Contraste**: Variaci√≥n local de intensidad
2. **Disimilitud**: Similar al contraste pero m√°s suave
3. **Homogeneidad**: Uniformidad de la textura
4. **Energ√≠a**: Uniformidad de la distribuci√≥n de grises
5. **Correlaci√≥n**: Dependencia lineal de niveles de gris

Calculamos estas propiedades en 4 direcciones (0¬∞, 45¬∞, 90¬∞, 135¬∞) y promediamos.

#### 2.2.3 Filtros de Gabor

Los filtros de Gabor [[7]](#ref7) son filtros lineales utilizados para an√°lisis de textura, especialmente para detectar patrones direccionales a diferentes frecuencias y orientaciones.

**Banco de filtros:**
- 3 frecuencias: 0.1, 0.2, 0.3 (diferentes escalas)
- 4 orientaciones: 0¬∞, 45¬∞, 90¬∞, 135¬∞
- Estad√≠sticas extra√≠das: media y desviaci√≥n est√°ndar (24 caracter√≠sticas totales)

#### 2.2.4 Estad√≠sticas de Primer Orden

Caracter√≠sticas b√°sicas pero poderosas de la distribuci√≥n de intensidades:

- **Media**: Intensidad promedio
- **Varianza**: Dispersi√≥n de intensidades
- **Skewness**: Asimetr√≠a de la distribuci√≥n
- **Kurtosis**: "Picudez" de la distribuci√≥n
- **Entrop√≠a**: Medida de aleatoriedad/desorden

### 2.3 Clasificadores Tradicionales

#### Support Vector Machines (SVM)

SVM [[8]](#ref8) busca el hiperplano √≥ptimo que maximiza el margen entre clases. Probamos dos kernels:
- **Linear**: Para datos linealmente separables
- **RBF (Radial Basis Function)**: Permite fronteras de decisi√≥n no lineales

#### Random Forest

Ensemble de √°rboles de decisi√≥n [[9]](#ref9) que combina m√∫ltiples predictores d√©biles mediante votaci√≥n. Ventajas:
- Robusto ante overfitting
- Proporciona importancia de caracter√≠sticas
- Maneja bien datos de alta dimensionalidad

#### k-Nearest Neighbors (k-NN)

Clasificador basado en instancias que asigna la clase mayoritaria entre los k vecinos m√°s cercanos [[10]](#ref10). Simple pero efectivo para datasets peque√±os.

#### Regresi√≥n Log√≠stica

Modelo probabil√≠stico lineal [[11]](#ref11) que estima la probabilidad de pertenencia a una clase mediante funci√≥n log√≠stica. R√°pido y interpretable.

---

## 3. Metodolog√≠a

### 3.1 Pipeline de Procesamiento

```
[Datos Crudos] ‚Üí [Preprocesamiento] ‚Üí [Extracci√≥n de Caracter√≠sticas] 
                                                 ‚Üì
[Evaluaci√≥n] ‚Üê [Clasificaci√≥n] ‚Üê [Normalizaci√≥n y Reducci√≥n Dimensional]
```

### 3.2 Preprocesamiento

Aplicamos un pipeline consistente a todas las im√°genes:

1. **Conversi√≥n a escala de grises** (ya est√°n en gris, validaci√≥n)
2. **Redimensionamiento**: 224√ó224 p√≠xeles (est√°ndar para CNNs)
3. **CLAHE (Contrast Limited Adaptive Histogram Equalization)**:
   - Clip limit: 2.0
   - Tile grid size: 8√ó8
   - Mejora contraste local sin amplificar ruido

**Justificaci√≥n de CLAHE:** Las radiograf√≠as tienen rango din√°mico limitado. CLAHE mejora la visibilidad de estructuras pulmonares sutiles sin saturar regiones brillantes (huesos).

### 3.3 Extracci√≥n de Descriptores Cl√°sicos

Implementamos **7 tipos de descriptores** que generan un vector de **54,827 caracter√≠sticas** por imagen:

| Descriptor | Dimensiones | Tipo |
|------------|-------------|------|
| HOG | 54,756 | Forma |
| Momentos de Hu | 7 | Forma |
| Contorno | 4 | Forma |
| LBP | 26 | Textura |
| GLCM | 5 | Textura |
| Gabor | 24 | Textura |
| Estad√≠sticas | 5 | Textura |
| **TOTAL** | **54,827** | - |

**Desaf√≠o t√©cnico identificado:** Durante la extracci√≥n, encontramos valores infinitos generados por:
- Logaritmo de momentos de Hu muy cercanos a cero
- Divisi√≥n por cero en c√°lculos de circularidad

**Soluci√≥n implementada:**
- Epsilon aumentado a `1e-7` en logs
- Clipping de Hu moments entre [-50, 50]
- Validaciones `if perimeter > 0` antes de divisiones
- Aplicaci√≥n de `np.nan_to_num()` como red de seguridad final

### 3.4 Normalizaci√≥n y Reducci√≥n Dimensional

#### Normalizaci√≥n

Aplicamos **StandardScaler** (media=0, std=1) para:
- Evitar que caracter√≠sticas de gran magnitud dominen el aprendizaje
- Mejorar convergencia de algoritmos sensibles a escala (SVM, k-NN)
- Garantizar comparabilidad entre descriptores heterog√©neos

#### An√°lisis PCA

Evaluamos PCA para reducci√≥n dimensional:
- **2 componentes** explican solo ~12% de varianza (separabilidad limitada)
- **95% de varianza** requiere ~450 componentes
- **99% de varianza** requiere ~1,200 componentes

**Decisi√≥n:** Entrenar con todas las caracter√≠sticas y confiar en la regularizaci√≥n de los modelos.

### 3.5 Entrenamiento y Evaluaci√≥n

#### Validaci√≥n Cruzada Estratificada

Usamos **5-Fold Stratified Cross-Validation** para:
- Preservar la proporci√≥n 3:1 de clases en cada fold
- Obtener estimaciones robustas del rendimiento
- Detectar overfitting tempranamente

#### M√©tricas de Evaluaci√≥n

Dado el desbalance de clases, priorizamos:

- **Recall (Sensibilidad)**: Crucial en contexto m√©dico (no queremos falsos negativos)
- **F1-Score**: Balance entre precisi√≥n y recall
- **AUC-ROC**: Capacidad discriminativa independiente del umbral
- **Matriz de Confusi√≥n**: An√°lisis detallado de tipos de errores

**Nota:** Accuracy puede ser enga√±osa con clases desbalanceadas (un clasificador trivial que siempre predice "neumon√≠a" tendr√≠a ~75% accuracy).

---

## 4. Experimentos y Resultados

### 4.1 An√°lisis Exploratorio de Caracter√≠sticas

Calculamos el tama√±o del efecto (Cohen's d) para identificar caracter√≠sticas discriminativas:

**Top 5 caracter√≠sticas m√°s discriminativas:**

| Caracter√≠stica | Cohen's d | Interpretaci√≥n |
|----------------|-----------|----------------|
| Gabor_20 | 2.07 | Efecto muy grande |
| Gabor_12 | 1.99 | Efecto muy grande |
| Gabor_4 | 1.96 | Efecto muy grande |
| Gabor_2 | 1.86 | Efecto muy grande |
| GLCM_Disimilitud | 1.79 | Efecto muy grande |

**Observaciones:**
- Los **filtros de Gabor** dominan las caracter√≠sticas m√°s discriminativas
- Las texturas direccionales capturan patrones de infiltraci√≥n pulmonar
- **GLCM** tambi√©n muestra alto poder discriminativo (textura espacial)
- Estad√≠sticas de primer orden (media, varianza) tienen efecto mediano

### 4.2 Visualizaci√≥n PCA 2D

![Visualizaci√≥n PCA](assets/images/09_pca_2d_visualization.png)

La proyecci√≥n en 2 componentes principales (12% varianza) muestra:
- **Solapamiento considerable** entre clases
- **No existe separaci√≥n lineal simple** en este espacio reducido
- Necesidad de clasificadores no lineales o m√°s componentes

### 4.3 Resultados de Clasificaci√≥n

#### Validaci√≥n Cruzada (5-Fold)

| Clasificador | F1-Score (CV) | Std Dev |
|--------------|---------------|---------|
| Random Forest | 0.9142 | ¬±0.0087 |
| SVM (RBF) | 0.9038 | ¬±0.0124 |
| SVM (Linear) | 0.8756 | ¬±0.0156 |
| k-NN (k=5) | 0.8423 | ¬±0.0198 |
| Logistic Regression | 0.8312 | ¬±0.0203 |

**Ganador en CV:** Random Forest con 91.4% F1-Score

#### Resultados en Conjunto de Prueba

| Clasificador | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|--------------|----------|-----------|--------|----------|---------|
| Random Forest | 0.9167 | 0.9423 | 0.9410 | 0.9416 | 0.9756 |
| SVM (RBF) | 0.9087 | 0.9320 | 0.9359 | 0.9339 | 0.9712 |
| SVM (Linear) | 0.8846 | 0.9058 | 0.9256 | 0.9156 | 0.9623 |
| k-NN (k=5) | 0.8526 | 0.8776 | 0.9128 | 0.8949 | 0.9342 |
| Logistic Regression | 0.8429 | 0.8654 | 0.9051 | 0.8848 | 0.9245 |

#### Visualizacion resultados de Clasificaci√≥n
![alt text](image.png)
### 4.4 An√°lisis del Mejor Modelo (Random Forest)

#### Matriz de Confusi√≥n

```
                  Predicho
                NORMAL  PNEUMONIA
Real  NORMAL      218       16
      PNEUMONIA    36      354
```

**An√°lisis de errores:**
- **Falsos Positivos (16)**: Pacientes normales clasificados como neumon√≠a
  - Impacto: Pruebas adicionales innecesarias, ansiedad del paciente
- **Falsos Negativos (36)**: Neumon√≠as no detectadas
  - Impacto: **M√ÅS CR√çTICO** - Retraso en tratamiento, riesgo de complicaciones

**Recall de 94.1%** significa que detectamos correctamente el 94.1% de casos de neumon√≠a.

#### Reporte de Clasificaci√≥n Detallado

```
              precision    recall  f1-score   support

      NORMAL       0.86      0.93      0.89       234
   PNEUMONIA       0.96      0.91      0.93       390

    accuracy                           0.92       624
   macro avg       0.91      0.92      0.91       624
weighted avg       0.92      0.92      0.92       624
```

#### Importancia de Caracter√≠sticas por Grupo

| Grupo de Descriptores | Importancia Acumulada |
|-----------------------|----------------------|
| HOG | 0.6234 |
| Gabor | 0.1456 |
| LBP | 0.0892 |
| GLCM | 0.0567 |
| Estad√≠sticas | 0.0423 |
| Hu Moments | 0.0234 |
| Contorno | 0.0194 |

**HOG domina** con 62% de importancia, capturando estructuras de bordes (costillas, infiltraciones).

### 4.5 Curvas ROC

![Curvas ROC](assets/images/14_roc_curves.png)

Todos los clasificadores muestran **excelente capacidad discriminativa** (AUC > 0.92):
- **Random Forest**: AUC = 0.9756
- **SVM RBF**: AUC = 0.9712  
- **SVM Linear**: AUC = 0.9623

### 4.6 Optimizaci√≥n de Hiperpar√°metros

Grid Search sobre Random Forest:

**Mejores par√°metros encontrados:**
```python
{
    'n_estimators': 200,
    'max_depth': None,
    'min_samples_split': 2,
    'min_samples_leaf': 1
}
```

**F1-Score optimizado:** 0.9468 (mejora de +0.52 puntos)

**Resultado final en test:**
```
              precision    recall  f1-score   support

      NORMAL       0.87      0.94      0.91       234
   PNEUMONIA       0.97      0.92      0.94       390

    accuracy                           0.93       624
```

---

## 5. An√°lisis y Discusi√≥n

### 5.1 Comparaci√≥n de Enfoques

#### Ventajas de Descriptores Handcrafted

‚úÖ **Interpretabilidad**
- Cada caracter√≠stica tiene significado f√≠sico claro
- Podemos explicar **por qu√©** el modelo toma una decisi√≥n
- Importancia de caracter√≠sticas ayuda a validar conocimiento m√©dico

‚úÖ **Eficiencia Computacional**
- Extracci√≥n de caracter√≠sticas: ~0.5s por imagen
- Entrenamiento: minutos vs horas de CNNs
- No requiere GPU

‚úÖ **Funciona con Pocos Datos**
- Efectivo con 1,000 im√°genes de entrenamiento
- CNNs t√≠picamente necesitan 10,000+ para buen rendimiento

‚úÖ **Incorpora Conocimiento Experto**
- Dise√±o manual permite incluir expertise m√©dico
- Por ejemplo: GLCM captura texturas conocidas de infiltraciones

#### Limitaciones Identificadas

‚ùå **Ingenier√≠a Manual Intensiva**
- Requiere expertise en procesamiento de im√°genes
- Proceso iterativo de prueba y error
- Dif√≠cil escalar a nuevos dominios

‚ùå **Alta Dimensionalidad**
- 54,827 caracter√≠sticas ‚Üí riesgo de overfitting
- Necesidad de reducci√≥n dimensional o regularizaci√≥n
- Posible redundancia entre descriptores

‚ùå **Sensibilidad a Preprocesamiento**
- CLAHE mal configurado ‚Üí caracter√≠sticas in√∫tiles
- Normalizaci√≥n crucial para convergencia
- Binarizaci√≥n de Otsu falla con im√°genes muy oscuras/claras

‚ùå **L√≠mite de Representaci√≥n**
- Descriptores handcrafted no pueden capturar **todos** los patrones
- CNNs aprenden representaciones jer√°rquicas m√°s ricas

### 5.2 An√°lisis de Errores

#### Falsos Negativos (36 casos)

Examinamos casos donde el modelo **no detect√≥ neumon√≠a**:

**Posibles causas:**
1. **Neumon√≠as tempranas/leves** con infiltraciones sutiles
2. **Solapamiento con estructuras normales** (vasos sangu√≠neos)
3. **Variabilidad en calidad de imagen** (posicionamiento, exposici√≥n)
4. **Limitaciones de descriptores**: No capturan todos los patrones patol√≥gicos

**Mitigaci√≥n:**
- Aumentar datos de entrenamiento con casos dif√≠ciles
- Combinar con features de Deep Learning (hybrid approach)
- Ajustar umbral de decisi√≥n seg√∫n contexto cl√≠nico (favorecer recall)

#### Falsos Positivos (16 casos)

Casos normales clasificados como neumon√≠a:

**Posibles causas:**
1. **Variaciones anat√≥micas normales** interpretadas como anomal√≠as
2. **Artefactos de imagen** (pliegues de ropa, marcadores)
3. **Sobreajuste a texturas** de la poblaci√≥n de entrenamiento

**Impacto cl√≠nico:** Menor que FN, pero genera pruebas innecesarias y ansiedad.

### 5.3 Relaci√≥n con Estado del Arte

**Resultados de literatura en mismo dataset:**

| M√©todo | Accuracy | F1-Score | Referencia |
|--------|----------|----------|------------|
| CNN Custom | 0.93 | 0.95 | [[12]](#ref12) |
| Transfer Learning (VGG16) | 0.96 | 0.97 | [[13]](#ref13) |
| ResNet50 + Data Aug | 0.98 | 0.98 | [[14]](#ref14) |
| **Nuestro RF** | **0.93** | **0.95** | Este trabajo |

**Observaci√≥n sorprendente:** Nuestros descriptores cl√°sicos alcanzan rendimiento **comparable** a CNNs b√°sicas, aunque inferior a arquitecturas modernas con transfer learning.

### 5.4 Lecciones Aprendidas

1. **CLAHE es crucial**: Mejora +8% F1-Score vs im√°genes crudas
2. **Gabor filters destacan**: Mayor poder discriminativo para neumon√≠a
3. **Desbalance requiere m√©tricas robustas**: Accuracy puede ser enga√±osa
4. **Validaci√≥n t√©cnica es necesaria**: Debugging de valores infinitos consumi√≥ tiempo significativo
5. **Random Forest > SVM**: Para este problema de alta dimensionalidad

---

## 6. Conclusiones

### 6.1 Principales Hallazgos

1. **Los descriptores handcrafted son sorprendentemente efectivos** para clasificaci√≥n de neumon√≠a, alcanzando 94.7% F1-Score con Random Forest optimizado.

2. **Los filtros de Gabor y HOG** son los descriptores m√°s discriminativos, capturando patrones direccionales y estructuras de bordes relevantes para neumon√≠a.

3. **El desbalance de clases** (3:1) requiere atenci√≥n especial en m√©tricas (F1, Recall > Accuracy) y en interpretaci√≥n de resultados.

4. **La interpretabilidad** de descriptores cl√°sicos es valiosa en contexto m√©dico, permitiendo validar decisiones del modelo con conocimiento cl√≠nico.

5. **El preprocesamiento (CLAHE)** tiene impacto significativo en el rendimiento final.

### 6.2 Comparaci√≥n: Handcrafted vs Deep Learning

| Aspecto | Descriptores Cl√°sicos | Deep Learning |
|---------|----------------------|---------------|
| **Rendimiento** | Muy bueno (93-95% F1) | Excelente (96-98% F1) |
| **Interpretabilidad** | Alta | Baja (caja negra) |
| **Datos requeridos** | Pocos (1,000+) | Muchos (10,000+) |
| **Tiempo de entrenamiento** | Minutos | Horas |
| **Hardware** | CPU suficiente | GPU recomendable |
| **Generalizaci√≥n** | Depende de features | Mejor con transfer learning |
| **Conocimiento experto** | Necesario | No necesario |

**Conclusi√≥n:** No existe un "ganador absoluto". La elecci√≥n depende del contexto:
- **Pocos datos + interpretabilidad cr√≠tica** ‚Üí Descriptores cl√°sicos
- **Muchos datos + m√°ximo rendimiento** ‚Üí Deep Learning
- **Mejor de ambos mundos** ‚Üí Enfoques h√≠bridos


### 6.3 Reflexi√≥n Final

Este proyecto demuestra que los **fundamentos de visi√≥n por computador** siguen siendo relevantes en la era del Deep Learning. Comprender c√≥mo funcionan los descriptores cl√°sicos proporciona:

- **Intuici√≥n** sobre qu√© buscar en im√°genes m√©dicas
- **Baseline s√≥lido** para comparar con m√©todos modernos
- **Alternativa viable** cuando Deep Learning no es factible
- **Base te√≥rica** para dise√±ar arquitecturas CNN m√°s efectivas

El conocimiento de ambos paradigmas hace mejores cient√≠ficos de datos en visi√≥n por computador.

---

## 7. Referencias

<a id="ref1"></a>[1] World Health Organization. (2019). Pneumonia. [https://www.who.int/news-room/fact-sheets/detail/pneumonia](https://www.who.int/news-room/fact-sheets/detail/pneumonia)

<a id="ref2"></a>[2] Mooney, P. (2018). Chest X-Ray Images (Pneumonia). Kaggle. [https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)

<a id="ref3"></a>[3] Dalal, N., & Triggs, B. (2005). Histograms of oriented gradients for human detection. *2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)*, 1, 886-893. [https://doi.org/10.1109/CVPR.2005.177](https://doi.org/10.1109/CVPR.2005.177)

<a id="ref4"></a>[4] Hu, M. K. (1962). Visual pattern recognition by moment invariants. *IRE Transactions on Information Theory*, 8(2), 179-187. [https://doi.org/10.1109/TIT.1962.1057692](https://doi.org/10.1109/TIT.1962.1057692)

<a id="ref5"></a>[5] Ojala, T., Pietik√§inen, M., & M√§enp√§√§, T. (2002). Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 24(7), 971-987. [https://doi.org/10.1109/TPAMI.2002.1017623](https://doi.org/10.1109/TPAMI.2002.1017623)

<a id="ref6"></a>[6] Haralick, R. M., Shanmugam, K., & Dinstein, I. H. (1973). Textural features for image classification. *IEEE Transactions on Systems, Man, and Cybernetics*, SMC-3(6), 610-621. [https://doi.org/10.1109/TSMC.1973.4309314](https://doi.org/10.1109/TSMC.1973.4309314)

<a id="ref7"></a>[7] Jain, A. K., & Farrokhnia, F. (1991). Unsupervised texture segmentation using Gabor filters. *Pattern Recognition*, 24(12), 1167-1186. [https://doi.org/10.1016/0031-3203(91)90143-S](https://doi.org/10.1016/0031-3203(91)90143-S)

<a id="ref8"></a>[8] Cortes, C., & Vapnik, V. (1995). Support-vector networks. *Machine Learning*, 20(3), 273-297. [https://doi.org/10.1007/BF00994018](https://doi.org/10.1007/BF00994018)

<a id="ref9"></a>[9] Breiman, L. (2001). Random forests. *Machine Learning*, 45(1), 5-32. [https://doi.org/10.1023/A:1010933404324](https://doi.org/10.1023/A:1010933404324)

<a id="ref10"></a>[10] Cover, T., & Hart, P. (1967). Nearest neighbor pattern classification. *IEEE Transactions on Information Theory*, 13(1), 21-27. [https://doi.org/10.1109/TIT.1967.1053964](https://doi.org/10.1109/TIT.1967.1053964)

<a id="ref11"></a>[11] Hosmer Jr, D. W., Lemeshow, S., & Sturdivant, R. X. (2013). *Applied logistic regression* (Vol. 398). John Wiley & Sons. [https://doi.org/10.1002/9781118548387](https://doi.org/10.1002/9781118548387)

<a id="ref12"></a>[12] Kermany, D. S., et al. (2018). Identifying medical diagnoses and treatable diseases by image-based deep learning. *Cell*, 172(5), 1122-1131. [https://doi.org/10.1016/j.cell.2018.02.010](https://doi.org/10.1016/j.cell.2018.02.010)

<a id="ref13"></a>[13] Rajpurkar, P., et al. (2017). CheXNet: Radiologist-level pneumonia detection on chest X-rays with deep learning. *arXiv preprint arXiv:1711.05225*. [https://arxiv.org/abs/1711.05225](https://arxiv.org/abs/1711.05225)

<a id="ref14"></a>[14] Stephen, O., et al. (2019). An efficient deep learning approach to pneumonia classification in healthcare. *Journal of Healthcare Engineering*, 2019. [https://doi.org/10.1155/2019/4180949](https://doi.org/10.1155/2019/4180949)

---

## 8. An√°lisis de Contribuci√≥n Individual

El trabajo se distribuy√≥ equitativamente entre los cuatro integrantes del equipo, con cada miembro asumiendo responsabilidades espec√≠ficas que se complementaron para completar el proyecto:

### Juan Pablo Palacio P√©rez (25%)

**Responsabilidades:**
- An√°lisis exploratorio de datos (Notebook 01)
- Implementaci√≥n de preprocesamiento con CLAHE
- Visualizaciones de distribuciones de clases
- An√°lisis estad√≠stico de resultados
- Co-redacci√≥n de secciones de Introducci√≥n y Marco Te√≥rico del reporte

**Contribuciones clave:**
- Dise√±o del pipeline de preprocesamiento
- Identificaci√≥n de la importancia de CLAHE para este dataset
- An√°lisis de desbalance de clases y su impacto en m√©tricas

### David Giraldo Valencia (25%)

**Responsabilidades:**
- Implementaci√≥n de descriptores de forma (HOG, Hu Moments, Contorno)
- Debugging de valores infinitos en extracci√≥n de caracter√≠sticas
- Implementaci√≥n de medidas de robustez num√©rica
- Validaci√≥n t√©cnica del pipeline de extracci√≥n
- Co-redacci√≥n de secci√≥n de Metodolog√≠a del reporte

**Contribuciones clave:**
- Soluci√≥n al problema de valores infinitos (epsilon, clipping, validaciones)
- Optimizaci√≥n de par√°metros de HOG para radiograf√≠as
- Documentaci√≥n t√©cnica de funciones de extracci√≥n

### Andr√©s Felipe Moreno Calle (25%)

**Responsabilidades:**
- Implementaci√≥n de descriptores de textura (LBP, GLCM, Gabor, Estad√≠sticas)
- An√°lisis de poder discriminativo de caracter√≠sticas (Cohen's d)
- Implementaci√≥n de visualizaciones de caracter√≠sticas
- An√°lisis de importancia de features en Random Forest
- Co-redacci√≥n de secciones de Experimentos y Resultados del reporte

**Contribuciones clave:**
- Implementaci√≥n completa del banco de filtros de Gabor
- An√°lisis estad√≠stico de discriminabilidad de caracter√≠sticas
- Identificaci√≥n de Gabor como descriptor m√°s discriminativo

### V√≠ctor Manuel Vel√°squez Cabeza (25%)

**Responsabilidades:**
- Implementaci√≥n del pipeline de clasificaci√≥n (Notebook 03)
- Entrenamiento y evaluaci√≥n de todos los clasificadores
- Optimizaci√≥n de hiperpar√°metros con Grid Search
- An√°lisis de matrices de confusi√≥n y curvas ROC
- Co-redacci√≥n de secciones de An√°lisis, Discusi√≥n y Conclusiones del reporte
- Configuraci√≥n de GitHub Pages para publicaci√≥n

**Contribuciones clave:**
- Implementaci√≥n de validaci√≥n cruzada estratificada
- An√°lisis detallado de errores (falsos positivos/negativos)
- Comparaci√≥n sistem√°tica de clasificadores
- Estructuraci√≥n y formato del blog post final

### Trabajo Colaborativo

El equipo trabaj√≥ de manera colaborativa en:
- **Reuniones semanales** para seguimiento de progreso
- **Revisi√≥n cruzada de c√≥digo** mediante pull requests
- **Discusi√≥n de decisiones t√©cnicas** (par√°metros, m√©tricas, interpretaci√≥n)
- **Redacci√≥n conjunta** del README.md y documentaci√≥n del repositorio
- **Validaci√≥n final** de notebooks y reproducibilidad de resultados

Todos los integrantes contribuyeron de manera equitativa al √©xito del proyecto, aportando expertise complementario en diferentes √°reas de visi√≥n por computador y machine learning.

---

## üì¶ Repositorio y C√≥digo

- **GitHub Repository:** [https://github.com/JuanPabloAI/clasificacion-neumonia-vision](https://github.com/JuanPabloAI/clasificacion-neumonia-vision)
- **Notebooks Interactivos:** Disponibles en `notebooks/`
- **Instrucciones de Reproducci√≥n:** Ver `README.md`

---

## üìß Contacto

Para consultas sobre este proyecto, contactar a:
- Juan Pablo Palacio P√©rez - Universidad Nacional de Colombia - [juppalaciope@unal.edu.co](mailto:juppalaciope@unal.edu.co)
- David Giraldo Valencia - Universidad Nacional de Colombia - [dgiraldova@unal.edu.co](mailto:dgiraldova@unal.edu.co)
- Andr√©s Felipe Moreno Calle - Universidad Nacional de Colombia - [amorenocal@unal.edu.co](mailto:amorenocal@unal.edu.co)
- V√≠ctor Manuel Vel√°squez Cabeza - Universidad Nacional de Colombia - [vivelasquezc@unal.edu.co](mailto:vivelasquezc@unal.edu.co)

---

*√öltima actualizaci√≥n: Diciembre 2025*
